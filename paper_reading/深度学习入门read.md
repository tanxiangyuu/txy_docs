# 深度学习入门

## 1. numpy 

广播，w*x为各个对应元素相乘。

## 2. 一些概念

w, b这些参数称为权重。



## 3. 批量归一化

<img src="C:\Users\河马\AppData\Roaming\Typora\typora-user-images\image-20230320133752353.png" alt="image-20230320133752353" style="zoom: 25%;" />

尝试把一个小批量中的数据的方差和均值固定 --标准化

和学习的参数为 γ 和 β：学出合适的偏移和缩放

作用在:

- 全连接层和卷积层输出上，激活函数前
- 全连接层和卷积层输入上

全连接 -- 特征维
卷积层 -- 通道维

批量归一化在做什么？

- 最初论文是想减少内部协变量转移
- 后续指出他可能就是通过在小批量里加入噪音来控制模型复杂度
- 没必要跟丢弃法混合使用

总结

- 把一个小批量中的数据的方差和均值固定，学出合适的偏移和缩放
- 可以加速收敛速度，但不改变模型精度。



## word2vec

Word2vec算法也用了Huffman编码，它把训练语料中的词当成叶子节点，其在语料中出现的次数当做权值，通过构造响应的Huffman树来对每一个词进行Huffman编码。

word2vec详细介绍：https://www.zybuluo.com/Dounm/note/591752
